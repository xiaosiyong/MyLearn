# 数据结构与算法

### 10个数据结构 数组、链表、栈、队列、散列表、二叉树、堆、跳表、图、trie树
### 10个算法 递归、排序、二分查找、搜索、哈希算法、贪心算法、分治算法、回溯算法、动态规划、字符串匹配算法

### 常见的复杂度量级（按数量级递增）
    * 常量阶 O(1)
    * 对数阶 O(logN)
    * 线性阶 O(N)
    * 线性对数阶 O(NlogN)
    * 平方阶 O(N*N)
    * 指数阶 O(2的N次幂)
    * 阶乘阶 O(N!)

数据结构就是指一组数据的存储结构。算法就是操作数据的一组方法。
数据结构是为算法服务的，算法要作用在特定的数据结构之上。

### 当同一块代码在不同的情况下，时间复杂度有量级的差距，才会使用三种复杂度（最好、最坏、平均时间复杂度）

数组是一种 **线性**的表数据结构，它用一组连续的内存空间，来存储一组具有相同类型的数据。同属于线性表结构的还有链表、队列、栈。与线性表对应的是 **非线性表**，比如二叉树、堆、图。

### 缓存淘汰策略常见的有三种：
    * 先进先出FIFO
    * 最少使用 Least Frequently Used
    * 最近最少使用 Least Recently Used

### 常用链表：单链表、双向链表、循环链表
链表的头结点记录链表的基地址，通过他遍历整条链表，尾节点指针指向一个空地址NULL
链表删除节点：
* 删除节点中”值等于某个给定值“的节点
* 删除给定指针指向的节点
对于第一种情况，单链表与双链表查找的时间复杂度都为O(n);
第二种情况，单链表为O(N),而双链表为O(1)。
插入、删除双链表都有优势，对于有序链表，双向链表的查询效率也较高。因为可以记录上次查找的位置P，每次查询时，与P比较，决定往前还是往后查找。

|     排序算法     | 时间复杂度  | 是否基于比较 |
| :--------------: | :---------: | :----------: |
| 冒泡、插入、选择 |   O(n*n)    |      是      |
|    快排、归并    | O（n*logn） |      是      |
|  捅、计数、基数  |    O(n)     |      否      |

如何分析一个排序算法：
### 执行效率
1、最好、最坏、平均情况时间复杂度

2、时间复杂度的系数、常数、低阶

3、比较次数和交换（移动）的次数
### 内存消耗
原地排序，特指空间复杂度是O（1）的排序算法
### 排序算法的稳定性
待排序的序列中存在等值元素，经过排序之后，顺序不变

### 有序度与逆序度
有序度：如果i<j 则a[i]<=a[j]

数组 2，4，3，1，5，6 有序度为11，因为有序元素对为11个：
（2，4）（2，3）（2，5）（2，6）
（4，5）（4，6）（3，5）（3，6）
（1，5）（1，6）（5，6）

对于一个完全有序的数组：有序度为**n*** **(n-1)/2**，把这种完全有序的数组的有序度叫满有序度。




插入排序比冒泡排序更受欢迎？原地排序算法？稳定的排序算法？

冒泡与插入时间复杂度都是**O（N*****N）**，都是原地排序算法，也是稳定的排序算法。但是冒泡排序需要数据交换，要三个复制操作，而插入排序只需要移动数据一次。大数据量下冒泡的时间是插入排序的7倍左右。

## 快速排序与归并排序
归并排序处理的过程由下到上，先处理子问题，然后再合并。快速排序正好相反，处理过程由上到下，先分区，再处理子问题。归并排序虽然是稳定的、时间复杂度为O（n*logN）的排序算法，但是它是非原地排序算法。
快速排序原定、不稳定的排序算法，大部分情况下时间复杂度可以做到 **O（N** **logN）**，极端情况下，会退化到 **O（N** **N）**

### 线性排序算法

桶排序、计数排序、基数排序

基数排序对要排序的数据有要求，需要可以分割出独立的“位”来比较，而且位之间有递进的关系，如果 a 数据的高位比b数据大，那剩下的低位就不用比较了。除此之外，每一位的数据范围不能太大，要可以用线性算法来排序，否则，基数排序时间复杂度无法做到O（n）。

桶排序和基数排序都是针对范围不大的数据，将数据划分成不同的桶来实现。基数排序要求数据可以划分成高低位，位之间有递进关系。比较两个数，我们只需要比较高位，高位相同的再比较低位。而且每一位的数据范围不能太大，因为基数排序算法需要借助桶排序或者计数排序来完成每一个位的排序工作

### 二分查找
数组元素中，留心下标是否越界。例如求中间元素时，如果mid=（low+high）/2,就有可能产生越界问题。
可改写成：mid=low+（high-low）>>1

### 解决Hash冲突的办法
1、开放寻址法
数据直接存储在数组中，有效利用CPU缓存加快查询速度。这种方法实现的散列表，序列化起来比较简单。链表法包含指针，序列化起来没那么容易。
开放寻址法中，由于所有数据在一个数组中，所以冲突的代价更高。所以开放寻址法解决冲突的散列表，装载因子的上限不能太大。所以也这种方法比较浪费内存空间。

当数据量比较小，装载因子小的时候，适合用开放寻址法。这也是Java ThreadLocalMap使用开放寻址法解决散列冲突的原因。

2、链表法
链表法对内存的利用率比开放寻址法高。比起开放寻址法，对大装载因子的容忍度更高。开放寻址法只能适用装载因子小于1的情况，接近1时，可能就会有大量的散列冲突，导致大量的探测、再散列，性能会下降。对于链表法来说，只要散列函数的值随机均匀，即便装载因子变成10，也就是链表的长度变成了，查找效率会下降，但比顺序查找还是快很多。
因为链表要存储指针，所以对于小对象存储，比较耗内存，还有可能让内存的消耗翻倍。而且因为链表中的节点是零散分布的，不连续的，所以对CPU缓存不友好。可将链表法中的链表改为其他高效的动态数据结构，比如跳表、红黑树。即使出现散列冲突，极端情况下，所有数据散列到同一个桶，查找时间O（logN）。**基于链表的散列冲突处理方法比较适合存储大对象、大数据量的散列表，比起开放寻址法，更加灵活，支持更多的优化策略，比如用红黑树代替链表**

### 哈希算法

将任意长度的二进制值串映射为固定长度的二进制值串，这个映射的规则叫 **哈希算法**，通过原始数据映射之后得到的二进制值串就是 **哈希值**。优秀哈希算法满足的要求：

- 从哈希值不能反向推导出原始数据(所以哈希算法也叫单向哈希算法)

- 对输入数据非常敏感，哪怕原始数据只修改了一个Bit，最后得到的哈希值也大不相同

- 散列冲突的概率要很小，对于不同的原始数据，哈希值相同的概率非常小

- 哈希算法的执行效率要尽量高效，针对较长的文本，也能快速的计算出哈希值。

  

哈希算法的应用：

安全加密、数据校验、唯一标识、散列函数、负载均衡、数据分片、分布式存储

关于"树"的概念，高度、深度、层
节点的高度 = 节点到叶子节点的最长路径（边数）
节点的深度 = 根节点到这个节点所经历的边的个数
节点的层数 = 及诶点的深度 + 1
树的高度 = 根节点的高度

![树](../images/tree.jpg)

二叉查找树：
在树中的任意一个节点，其左子树中的每个节点的值，都要小于这个节点的值，而右子树节点的值都大于这个节点的值。
支持快速插入、删除、查找操作，各个操作的时间复杂度跟树的高度成正比，理想情况下，时间复杂度是O（logN）

平衡二叉树：
二叉树中任意一个节点的左右子树的高度相差不能大于1。
平衡二叉查找树中"平衡"的意思，是让整棵树左右看起来比较"对称"，比较"平衡"，不要出现左子树很高、右子树很矮的情况。这样就能让整棵树的高度相对来说低一些，相应的插入、删除、查找等操作的效率高一些。

**红黑树由2-3树的演变**
<<<<<<< HEAD:算法/DataStructAndAlgorithm.md

#### 字符串匹配算法之----BF算法、RK算法、BM算法和KMP算法

1、BF算法

Brute Force的缩写，中文也叫暴力匹配算法，朴素匹配算法。其思想是：在主串中，检查起始位置分别是0、1、2…n-m且长度为m的n-m+1个子串，看有没有跟模式串匹配的，其中主串长度为n，模式串长度为m。时间复杂度比较高，是O(n*m),n、m表示主串和模式串的长度。

2、RK算法

全称叫Rabin-Karp算法，算法的思路：通过哈希算法对主串中的 n-m+1个子串分别求哈希值，然后逐个与模式串的哈希值比较大小。哈希算法的设计：假设要匹配的字符串的字符集中只包含K个字符，我们可以用一个K进制数来表示一个子串，这个K进制数转化成十进制数，作为子串的哈希值。比如要处理的字符串只包含a~z这26个小写字母，则用二十六进制来表示一个字符串。a~z映射0~25这26个数字，a表示0，b表示1……z表示25.那么cba=c X26X26+bX26+aX1=1353。通过这种特殊的哈希算法，只需要扫描一遍主串就能计算出所有子串的哈希值了。RK算法的时间复杂度是O(n),跟BF算法相比，效率提高了很多，但是效率取决于哈希算法的设计。如果存在大量哈希冲突，极端情况下，会退化为O(n*m)。

3、BM算法

Boyer-Moore算法，核心思想是，利用模式串本身的特点，在模式串中某个字符与主串不能匹配的时候，讲模式串往后多滑几位，以此来减少不必要的字符比较，提高匹配效率。BM算法构建的规则有两类，坏字符规则和好后缀规则。好后缀规则可以独立于坏字符规则使用。坏字符规则的实现比较耗内存，为了省内存，可以只用好后缀规则来实现BM算法。

3.1 坏字符规则

BM算法的匹配顺序是按照模式串下标从大到小的顺序，倒着匹配。

![matchrule](../images/matchrule.jpg)

当发现某个字符没法匹配的时候，把这个没有匹配的字符叫**坏字符**，比如上图中c是坏字符。当发生不匹配的时候，我们把坏字符对应的模式串中的字符下标记作 si。如果坏字符在模式串中存在，我们把这个坏字符在模式串中的下标记作 xi。如果不存在，我们把 xi 记作 -1。那模式串往后移动的位数就等于 si-xi。（注意，我这里说的下标，都是字符在模式串的下标）。如果坏字符在模式串里多次出现，我们在计算Xi的时候，选择最靠后的那个，因为这样不会让模式串滑动过多，导致本来可能匹配的情况被滑过。如下图：

![badindex](../images/badindex.jpg)

单纯使用坏字符规则还是不够的，因为根据si-xi计算出来的移动位数，可能是负数，比如主串aaaaaaaaaaaaaaa，模式串baaa。这种不但不会向后滑动模式串，还可能倒退。所以，BM算法还需要用到"好后缀规则"。

3.2好后缀规则

好后缀规则跟坏字符规则类似，滑动过程中，匹配到的字符称为好后缀，未匹配的称为坏字符，如下图：

![goodprex](../images/goodprex.png)

我们把已经匹配的bc叫好后缀，记为{u}。拿它在模式串中查找，如果找到了另一个跟{u}相匹配的子串{u*}，那么就将模式串滑动到子串{u\*}对齐的位置。如图：

![match](../images/match.png)

如果模式串中找不到另一个等于{u}的子串，就直接将模式串，滑动到主串中{u}的后面，因为之前的任何一次往后滑动，都没有匹配主串中{u}的情况。如图：

![nomatch](../images/nomatch.png)

但是上述的这种情况有时候也会滑动过头，来看下边这个例子，bc是好后缀，尽管在模式串中没有另外一个相匹配的子串{u\*},但是如果我们将模式串移动到好后缀的后面，会错过模式串和主串可以匹配的情况。如图：

![miss](../images/miss.jpg)

如果好后缀在模式串中不存在可匹配的子串，那在我们一步一步往后滑动模式串的过程中，只要主串中的{u}与模式串有重合，那肯定就无法完全匹配。但是当模式串滑动到前缀与主串中{u}的后缀有部分重合的时候，并且重合的部分相等的时候，就有可能会存在完全匹配的情况。如图：

![WX20190723](../images/WX20190723.png)

针对这种情况，不仅要看好后缀在模式串中，是否有另一个匹配的子串，我们还要考察好后缀的后缀子串，是否存在跟模式串的前缀子串匹配的。所谓某个字符串 s 的后缀子串，就是最后一个字符跟 s 对齐的子串，比如 abc 的后缀子串就包括 c, bc。所谓前缀子串，就是起始字符跟 s 对齐的子串，比如 abc 的前缀子串有 a，ab。我们从好后缀的后缀子串中，找一个最长的并且能跟模式串的前缀子串匹配的，假设是{v}，然后将模式串滑动到如图所示的位置。

![masterstring](../images/masterstring.png)

当模式串和主串中的某个字符不匹配的时候，**我们分别计算好后缀和坏字符往后滑动的位数，然后取两个数中最大的，作为模式串往后滑动的位数**。
=======
>>>>>>> 1f11d04c2c91f1d788c7d91a19b23c58bb8a4463:算法/数据结构与算法之美.md
